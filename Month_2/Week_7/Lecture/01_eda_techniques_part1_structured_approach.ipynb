{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "structured_eda_title"
      },
      "source": [
        "# Week 7: EDA Techniques - Part 1: Structured EDA Approach and Framework\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this session, you will be able to:\n",
        "- Understand the systematic approach to Exploratory Data Analysis\n",
        "- Apply structured EDA frameworks to real business datasets\n",
        "- Create reproducible EDA workflows\n",
        "- Connect to live databases for real-time analysis\n",
        "\n",
        "## Business Context\n",
        "Today we're working with **live Olist Brazilian e-commerce data** from our Supabase database. This represents real customer transactions, product catalogs, and business operations from one of Brazil's largest marketplaces.\n",
        "\n",
        "**Key Business Questions:**\n",
        "- What patterns exist in our customer behavior?\n",
        "- How do different product categories perform?\n",
        "- What geographic trends can we identify?\n",
        "- How can we structure our analysis for maximum business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## 1. Environment Setup and Data Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_imports"
      },
      "outputs": [],
      "source": [
        "# Standard imports for data analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Database connection\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "database_connection"
      },
      "outputs": [],
      "source": [
        "# Supabase connection details\n",
        "DATABASE_URL = \"postgresql://postgres.pzykoxdiwsyclwfqfiii:L3tMeQuery123!@aws-0-us-east-1.pooler.supabase.com:6543/postgres\"\n",
        "\n",
        "# Create database engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Test connection\n",
        "try:\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(\"SELECT 1 as test\")\n",
        "        print(\"‚úÖ Database connection successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Connection failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eda_framework_section"
      },
      "source": [
        "## 2. The Structured EDA Framework\n",
        "\n",
        "### The 5-Step EDA Process\n",
        "\n",
        "1. **Data Discovery** - What data do we have?\n",
        "2. **Data Quality Assessment** - How clean is our data?\n",
        "3. **Initial Exploration** - What patterns are immediately visible?\n",
        "4. **Deep Dive Analysis** - What insights can we extract?\n",
        "5. **Business Insights** - What actions can we recommend?\n",
        "\n",
        "### Why This Matters for Business\n",
        "- **Systematic approach** ensures nothing is missed\n",
        "- **Reproducible process** can be applied to any dataset\n",
        "- **Business-focused** analysis drives actionable insights\n",
        "- **Time-efficient** method prevents analysis paralysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_discovery"
      },
      "source": [
        "## Step 1: Data Discovery\n",
        "\n",
        "Let's start by understanding what data we have available in our Olist database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_tables"
      },
      "outputs": [],
      "source": [
        "# Query to see all available tables\n",
        "tables_query = \"\"\"\n",
        "SELECT \n",
        "    schemaname,\n",
        "    tablename,\n",
        "    tableowner\n",
        "FROM pg_tables \n",
        "WHERE schemaname IN ('olist_sales_data_set', 'olist_marketing_data_set')\n",
        "ORDER BY schemaname, tablename;\n",
        "\"\"\"\n",
        "\n",
        "available_tables = pd.read_sql(tables_query, engine)\n",
        "print(\"üìä Available Tables in Our Database:\")\n",
        "print(\"=\" * 50)\n",
        "display(available_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_main_datasets"
      },
      "outputs": [],
      "source": [
        "# Load our main datasets for analysis\n",
        "print(\"üîÑ Loading main datasets...\")\n",
        "\n",
        "# Orders data - our primary transaction data\n",
        "orders_query = \"SELECT * FROM olist_sales_data_set.olist_orders_dataset LIMIT 5000\"\n",
        "orders_df = pd.read_sql(orders_query, engine)\n",
        "\n",
        "# Customers data\n",
        "customers_query = \"SELECT * FROM olist_sales_data_set.olist_customers_dataset LIMIT 5000\"\n",
        "customers_df = pd.read_sql(customers_query, engine)\n",
        "\n",
        "# Products data\n",
        "products_query = \"SELECT * FROM olist_sales_data_set.olist_products_dataset\"\n",
        "products_df = pd.read_sql(products_query, engine)\n",
        "\n",
        "# Order items data\n",
        "order_items_query = \"SELECT * FROM olist_sales_data_set.olist_order_items_dataset LIMIT 10000\"\n",
        "order_items_df = pd.read_sql(order_items_query, engine)\n",
        "\n",
        "print(\"‚úÖ Data loaded successfully!\")\n",
        "print(f\"üìà Orders: {len(orders_df):,} records\")\n",
        "print(f\"üë• Customers: {len(customers_df):,} records\")\n",
        "print(f\"üì¶ Products: {len(products_df):,} records\")\n",
        "print(f\"üõí Order Items: {len(order_items_df):,} records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_overview_section"
      },
      "source": [
        "## Step 2: Data Quality Assessment\n",
        "\n",
        "Before diving into analysis, we need to understand the quality and structure of our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_overview_function"
      },
      "outputs": [],
      "source": [
        "def data_overview(df, name):\n",
        "    \"\"\"\n",
        "    Comprehensive data overview function for EDA\n",
        "    \"\"\"\n",
        "    print(f\"\\nüìä {name} Dataset Overview\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Basic info\n",
        "    print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
        "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "    \n",
        "    # Data types\n",
        "    print(\"\\nüìã Data Types:\")\n",
        "    dtype_counts = df.dtypes.value_counts()\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\"  {dtype}: {count} columns\")\n",
        "    \n",
        "    # Missing values\n",
        "    print(\"\\n‚ùì Missing Values:\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df)) * 100\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Column': missing.index,\n",
        "        'Missing Count': missing.values,\n",
        "        'Missing %': missing_pct.values\n",
        "    })\n",
        "    missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
        "    \n",
        "    if len(missing_df) > 0:\n",
        "        display(missing_df.head(10))\n",
        "    else:\n",
        "        print(\"  ‚úÖ No missing values found!\")\n",
        "    \n",
        "    # Sample data\n",
        "    print(\"\\nüëÄ Sample Data:\")\n",
        "    display(df.head(3))\n",
        "    \n",
        "    return missing_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_orders"
      },
      "outputs": [],
      "source": [
        "# Analyze orders dataset\n",
        "orders_missing = data_overview(orders_df, \"Orders\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_customers"
      },
      "outputs": [],
      "source": [
        "# Analyze customers dataset\n",
        "customers_missing = data_overview(customers_df, \"Customers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_products"
      },
      "outputs": [],
      "source": [
        "# Analyze products dataset\n",
        "products_missing = data_overview(products_df, \"Products\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_initial_exploration"
      },
      "source": [
        "## Step 3: Initial Exploration\n",
        "\n",
        "Now let's start exploring patterns in our data using systematic approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "order_status_analysis"
      },
      "outputs": [],
      "source": [
        "# Order Status Analysis - Understanding our business pipeline\n",
        "print(\"üìä Order Status Distribution\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "status_counts = orders_df['order_status'].value_counts()\n",
        "status_pct = (status_counts / len(orders_df)) * 100\n",
        "\n",
        "status_summary = pd.DataFrame({\n",
        "    'Count': status_counts,\n",
        "    'Percentage': status_pct.round(2)\n",
        "})\n",
        "\n",
        "display(status_summary)\n",
        "\n",
        "# Visualize order status\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "status_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Order Status Distribution (Count)')\n",
        "plt.xlabel('Order Status')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Order Status Distribution (%)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Business insight\n",
        "delivered_pct = status_pct.get('delivered', 0)\n",
        "print(f\"\\nüí° Business Insight: {delivered_pct:.1f}% of orders are successfully delivered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "temporal_analysis"
      },
      "outputs": [],
      "source": [
        "# Temporal Analysis - Understanding order patterns over time\n",
        "print(\"üìÖ Temporal Analysis of Orders\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Convert timestamp to datetime\n",
        "orders_df['order_purchase_timestamp'] = pd.to_datetime(orders_df['order_purchase_timestamp'])\n",
        "\n",
        "# Extract temporal features\n",
        "orders_df['order_year'] = orders_df['order_purchase_timestamp'].dt.year\n",
        "orders_df['order_month'] = orders_df['order_purchase_timestamp'].dt.month\n",
        "orders_df['order_day_of_week'] = orders_df['order_purchase_timestamp'].dt.dayofweek\n",
        "orders_df['order_hour'] = orders_df['order_purchase_timestamp'].dt.hour\n",
        "\n",
        "# Orders by year\n",
        "yearly_orders = orders_df['order_year'].value_counts().sort_index()\n",
        "print(\"\\nüìà Orders by Year:\")\n",
        "for year, count in yearly_orders.items():\n",
        "    print(f\"  {year}: {count:,} orders\")\n",
        "\n",
        "# Visualize temporal patterns\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Orders by month\n",
        "plt.subplot(2, 2, 1)\n",
        "monthly_orders = orders_df['order_month'].value_counts().sort_index()\n",
        "monthly_orders.plot(kind='bar', color='lightcoral')\n",
        "plt.title('Orders by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Orders by day of week\n",
        "plt.subplot(2, 2, 2)\n",
        "dow_orders = orders_df['order_day_of_week'].value_counts().sort_index()\n",
        "dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "dow_orders.index = [dow_labels[i] for i in dow_orders.index]\n",
        "dow_orders.plot(kind='bar', color='lightgreen')\n",
        "plt.title('Orders by Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Orders by hour\n",
        "plt.subplot(2, 2, 3)\n",
        "hourly_orders = orders_df['order_hour'].value_counts().sort_index()\n",
        "hourly_orders.plot(kind='line', marker='o', color='gold')\n",
        "plt.title('Orders by Hour of Day')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Time series of orders\n",
        "plt.subplot(2, 2, 4)\n",
        "orders_df.set_index('order_purchase_timestamp').resample('D').size().plot(color='purple', alpha=0.7)\n",
        "plt.title('Daily Orders Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Business insights\n",
        "peak_hour = hourly_orders.idxmax()\n",
        "peak_day = dow_labels[dow_orders.idxmax()]\n",
        "print(f\"\\nüí° Business Insights:\")\n",
        "print(f\"   ‚Ä¢ Peak ordering hour: {peak_hour}:00\")\n",
        "print(f\"   ‚Ä¢ Peak ordering day: {peak_day}\")\n",
        "print(f\"   ‚Ä¢ Most active month: {monthly_orders.idxmax()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geographic_analysis"
      },
      "source": [
        "## Geographic Analysis - Customer Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "customer_geographic"
      },
      "outputs": [],
      "source": [
        "# Geographic distribution of customers\n",
        "print(\"üó∫Ô∏è Geographic Analysis\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "# Top states by customer count\n",
        "state_counts = customers_df['customer_state'].value_counts().head(10)\n",
        "print(\"\\nüèÜ Top 10 States by Customer Count:\")\n",
        "for state, count in state_counts.items():\n",
        "    pct = (count / len(customers_df)) * 100\n",
        "    print(f\"   {state}: {count:,} customers ({pct:.1f}%)\")\n",
        "\n",
        "# Top cities by customer count\n",
        "city_counts = customers_df['customer_city'].value_counts().head(10)\n",
        "print(\"\\nüèôÔ∏è Top 10 Cities by Customer Count:\")\n",
        "for city, count in city_counts.items():\n",
        "    pct = (count / len(customers_df)) * 100\n",
        "    print(f\"   {city}: {count:,} customers ({pct:.1f}%)\")\n",
        "\n",
        "# Visualize geographic distribution\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "state_counts.plot(kind='bar', color='lightblue')\n",
        "plt.title('Top 10 States by Customer Count')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "city_counts.plot(kind='bar', color='orange')\n",
        "plt.title('Top 10 Cities by Customer Count')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Geographic concentration analysis\n",
        "total_customers = len(customers_df)\n",
        "top_5_states_pct = (state_counts.head(5).sum() / total_customers) * 100\n",
        "top_5_cities_pct = (city_counts.head(5).sum() / total_customers) * 100\n",
        "\n",
        "print(f\"\\nüí° Geographic Concentration:\")\n",
        "print(f\"   ‚Ä¢ Top 5 states account for {top_5_states_pct:.1f}% of customers\")\n",
        "print(f\"   ‚Ä¢ Top 5 cities account for {top_5_cities_pct:.1f}% of customers\")\n",
        "print(f\"   ‚Ä¢ Total unique states: {customers_df['customer_state'].nunique()}\")\n",
        "print(f\"   ‚Ä¢ Total unique cities: {customers_df['customer_city'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "framework_summary"
      },
      "source": [
        "## EDA Framework Summary\n",
        "\n",
        "### What We've Accomplished\n",
        "\n",
        "1. **‚úÖ Data Discovery**: Identified available datasets and their relationships\n",
        "2. **‚úÖ Quality Assessment**: Analyzed data types, missing values, and data integrity\n",
        "3. **‚úÖ Initial Exploration**: Uncovered key patterns in:\n",
        "   - Order processing pipeline\n",
        "   - Temporal ordering patterns\n",
        "   - Geographic customer distribution\n",
        "\n",
        "### Key Business Insights So Far\n",
        "\n",
        "**Order Processing:**\n",
        "- Most orders are successfully delivered\n",
        "- Clear operational pipeline from purchase to delivery\n",
        "\n",
        "**Customer Behavior:**\n",
        "- Peak ordering times and days identified\n",
        "- Strong geographic concentration in specific regions\n",
        "- Seasonal patterns in ordering behavior\n",
        "\n",
        "### Next Steps\n",
        "In the next parts, we'll dive deeper into:\n",
        "- Descriptive statistics and summary insights\n",
        "- Distribution analysis and correlation exploration\n",
        "- Advanced customer segmentation techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "practical_exercises"
      },
      "source": [
        "## üéØ Practice Exercises\n",
        "\n",
        "Try these exercises to reinforce your understanding:\n",
        "\n",
        "1. **Data Quality Check**: Create a function that checks for duplicate records in the orders dataset\n",
        "\n",
        "2. **Temporal Analysis**: Analyze the time difference between order purchase and delivery dates\n",
        "\n",
        "3. **Geographic Insights**: Find the average number of customers per city for each state\n",
        "\n",
        "4. **Data Validation**: Check if all customer_ids in orders exist in the customers table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_space"
      },
      "outputs": [],
      "source": [
        "# Exercise space - try the exercises above!\n",
        "\n",
        "# Exercise 1: Check for duplicates\n",
        "def check_duplicates(df, column_name):\n",
        "    \"\"\"\n",
        "    Check for duplicate records in a specific column\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Exercise 2: Delivery time analysis\n",
        "# Your code here\n",
        "\n",
        "# Exercise 3: Geographic analysis\n",
        "# Your code here\n",
        "\n",
        "# Exercise 4: Data validation\n",
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}