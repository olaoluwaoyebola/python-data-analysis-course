{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "product_performance_title"
      },
      "source": [
        "# Week 7: Advanced EDA with Business Intelligence - Part 2: Product Performance Metrics and Insights\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this session, you will be able to:\n",
        "- Conduct comprehensive product performance analysis using advanced EDA techniques\n",
        "- Implement product lifecycle and portfolio analysis strategies\n",
        "- Apply advanced metrics for product success measurement\n",
        "- Create data-driven product recommendations and optimization strategies\n",
        "- Build product performance dashboards for business intelligence\n",
        "\n",
        "## Business Context\n",
        "Building on our customer behavior insights, we now focus on **product performance analytics** to understand:\n",
        "- **Product Success Drivers**: What makes certain products outperform others?\n",
        "- **Category Performance**: Which product categories drive the most value?\n",
        "- **Cross-selling Opportunities**: Which products are frequently bought together?\n",
        "- **Inventory Optimization**: How to optimize product mix based on performance data?\n",
        "\n",
        "**Key Business Questions:**\n",
        "- Which products and categories generate the highest revenue and profit?\n",
        "- What are the patterns in product performance across different dimensions?\n",
        "- How can we identify products with cross-selling potential?\n",
        "- Which products are underperforming and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section_product"
      },
      "source": [
        "## 1. Environment Setup and Secure Data Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "product_setup"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        </script>\n",
              "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.1.min\"</script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Environment setup complete for product performance analysis!\n"
          ]
        }
      ],
      "source": [
        "# Essential imports for product performance analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Advanced analytics libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Network analysis for product relationships\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "\n",
        "# Advanced visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "pyo.init_notebook_mode(connected=True)\n",
        "\n",
        "# Database connection (secure)\n",
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Display and plotting settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "\n",
        "print(\"âœ… Environment setup complete for product performance analysis!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "secure_product_connection"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âŒ Connection failed: (psycopg2.OperationalError) connection to server at \"aws-0-us-east-1.pooler.supabase.com\" (52.45.94.125), port 6543 failed: FATAL:  Tenant or user not found\n",
            "connection to server at \"aws-0-us-east-1.pooler.supabase.com\" (52.45.94.125), port 6543 failed: FATAL:  Tenant or user not found\n",
            "\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
            "ðŸ”’ Security Note: Database credentials loaded from environment variables\n"
          ]
        }
      ],
      "source": [
        "# Secure Database Connection Using Environment Variables\n",
        "# Best practice: Never expose credentials in code\n",
        "\n",
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Read database credentials from environment variables\n",
        "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
        "SUPABASE_KEY = os.getenv('SUPABASE_KEY')\n",
        "\n",
        "# Alternative: Use legacy postgres connection if needed\n",
        "POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
        "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '6543')\n",
        "POSTGRES_DB = os.getenv('POSTGRES_DATABASE', 'postgres')\n",
        "POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
        "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
        "\n",
        "# Construct secure database URL using environment variables\n",
        "if POSTGRES_HOST and POSTGRES_USER and POSTGRES_PASSWORD:\n",
        "    DATABASE_URL = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
        "else:\n",
        "    print(\"âŒ Database credentials not found in environment variables\")\n",
        "    print(\"Please check your .env file contains the required database credentials\")\n",
        "\n",
        "# Create database engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Test connection\n",
        "try:\n",
        "    with engine.connect() as conn:\n",
        "        from sqlalchemy import text\n",
        "        result = conn.execute(text(\"SELECT count(*) FROM olist_sales_data_set.olist_geolocation_dataset\"))\n",
        "        count = result.scalar()\n",
        "        print(f\"âœ… Secure database connection established! ({count:,} records in geolocation table)\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Connection failed: {e}\")\n",
        "\n",
        "print(\"ðŸ”’ Security Note: Database credentials loaded from .env file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "product_data_loading"
      },
      "source": [
        "## 2. Comprehensive Product Data Loading\n",
        "\n",
        "Load detailed product performance data for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_product_data"
      },
      "outputs": [],
      "source": [
        "# Comprehensive Product Performance Dataset\n",
        "print(\"ðŸ”„ Loading comprehensive product performance dataset...\")\n",
        "\n",
        "# Product performance and analytics query\n",
        "product_performance_query = \"\"\"\n",
        "WITH product_sales AS (\n",
        "    SELECT \n",
        "        p.product_id,\n",
        "        p.product_category_name,\n",
        "        COALESCE(pt.product_category_name_english, p.product_category_name) as category_english,\n",
        "        p.product_weight_g,\n",
        "        p.product_length_cm,\n",
        "        p.product_height_cm,\n",
        "        p.product_width_cm,\n",
        "        p.product_photos_qty,\n",
        "        p.product_name_lenght,\n",
        "        p.product_description_lenght,\n",
        "        (p.product_length_cm * p.product_height_cm * p.product_width_cm) / 1000.0 as product_volume_liters,\n",
        "        \n",
        "        oi.order_id,\n",
        "        oi.price,\n",
        "        oi.freight_value,\n",
        "        (oi.price + oi.freight_value) as total_item_value,\n",
        "        oi.freight_value / NULLIF(oi.price, 0) as freight_ratio,\n",
        "        \n",
        "        o.order_purchase_timestamp,\n",
        "        o.customer_id,\n",
        "        EXTRACT(YEAR FROM o.order_purchase_timestamp) as order_year,\n",
        "        EXTRACT(MONTH FROM o.order_purchase_timestamp) as order_month,\n",
        "        EXTRACT(QUARTER FROM o.order_purchase_timestamp) as order_quarter,\n",
        "        \n",
        "        c.customer_state,\n",
        "        c.customer_city,\n",
        "        \n",
        "        r.review_score,\n",
        "        CASE \n",
        "            WHEN r.review_score >= 4 THEN 'High'\n",
        "            WHEN r.review_score = 3 THEN 'Medium'\n",
        "            WHEN r.review_score <= 2 THEN 'Low'\n",
        "            ELSE 'No Review'\n",
        "        END as satisfaction_category\n",
        "        \n",
        "    FROM olist_sales_data_set.olist_products_dataset p\n",
        "    JOIN olist_sales_data_set.olist_order_items_dataset oi ON p.product_id = oi.product_id\n",
        "    JOIN olist_sales_data_set.olist_orders_dataset o ON oi.order_id = o.order_id\n",
        "    JOIN olist_sales_data_set.olist_customers_dataset c ON o.customer_id = c.customer_id\n",
        "    LEFT JOIN olist_sales_data_set.product_category_name_translation pt \n",
        "        ON p.product_category_name = pt.product_category_name\n",
        "    LEFT JOIN olist_sales_data_set.olist_order_reviews_dataset r ON o.order_id = r.order_id\n",
        "    \n",
        "    WHERE o.order_status = 'delivered'\n",
        "    AND oi.price > 0\n",
        ")\n",
        "SELECT * FROM product_sales\n",
        "LIMIT 30000;\n",
        "\"\"\"\n",
        "\n",
        "# Load the data\n",
        "product_df = pd.read_sql(product_performance_query, engine)\n",
        "\n",
        "# Data preprocessing\n",
        "product_df['order_purchase_timestamp'] = pd.to_datetime(product_df['order_purchase_timestamp'])\n",
        "product_df['category_clean'] = product_df['category_english'].fillna('Unknown').str.title()\n",
        "\n",
        "# Calculate additional business metrics\n",
        "product_df['profit_margin'] = (product_df['price'] - product_df['freight_value']) / product_df['price']\n",
        "product_df['price_per_gram'] = product_df['price'] / (product_df['product_weight_g'] + 1)  # +1 to avoid division by zero\n",
        "product_df['price_per_liter'] = product_df['price'] / (product_df['product_volume_liters'] + 1)\n",
        "\n",
        "# Remove extreme outliers for better analysis\n",
        "price_q99 = product_df['price'].quantile(0.99)\n",
        "product_df = product_df[product_df['price'] <= price_q99].copy()\n",
        "\n",
        "print(f\"âœ… Product performance dataset loaded successfully!\")\n",
        "print(f\"   ðŸ“Š Total records: {len(product_df):,}\")\n",
        "print(f\"   ðŸ“¦ Unique products: {product_df['product_id'].nunique():,}\")\n",
        "print(f\"   ðŸ›’ Unique orders: {product_df['order_id'].nunique():,}\")\n",
        "print(f\"   ðŸ·ï¸ Product categories: {product_df['category_clean'].nunique()}\")\n",
        "print(f\"   ðŸ“… Analysis period: {product_df['order_purchase_timestamp'].min().date()} to {product_df['order_purchase_timestamp'].max().date()}\")\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nðŸ“‹ Sample Product Performance Data:\")\n",
        "display(product_df[['product_id', 'category_clean', 'price', 'total_item_value', \n",
        "                  'review_score', 'satisfaction_category']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "product_portfolio_section"
      },
      "source": [
        "## 3. Product Portfolio Analysis\n",
        "\n",
        "Comprehensive analysis of product performance across multiple dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "product_portfolio_analysis"
      },
      "outputs": [],
      "source": [
        "# Product Portfolio Performance Analysis\n",
        "print(\"ðŸ“Š Product Portfolio Performance Analysis\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "def analyze_product_portfolio(data):\n",
        "    \"\"\"\n",
        "    Comprehensive product portfolio analysis\n",
        "    \"\"\"\n",
        "    portfolio_analysis = {}\n",
        "    \n",
        "    # Product-level metrics\n",
        "    product_metrics = data.groupby('product_id').agg({\n",
        "        'price': ['count', 'mean', 'std'],\n",
        "        'total_item_value': ['sum', 'mean'],\n",
        "        'review_score': ['mean', 'count'],\n",
        "        'order_id': 'nunique',  # Number of unique orders\n",
        "        'customer_id': 'nunique',  # Number of unique customers\n",
        "        'freight_value': 'mean',\n",
        "        'profit_margin': 'mean',\n",
        "        'category_clean': 'first',\n",
        "        'product_weight_g': 'first',\n",
        "        'product_volume_liters': 'first'\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Flatten column names\n",
        "    product_metrics.columns = [\n",
        "        'product_id', 'sales_volume', 'avg_price', 'price_std', \n",
        "        'total_revenue', 'avg_order_value', 'avg_review_score', 'review_count',\n",
        "        'unique_orders', 'unique_customers', 'avg_freight', 'avg_profit_margin',\n",
        "        'category', 'weight_g', 'volume_liters'\n",
        "    ]\n",
        "    \n",
        "    # Calculate additional metrics\n",
        "    product_metrics['revenue_per_customer'] = product_metrics['total_revenue'] / product_metrics['unique_customers']\n",
        "    product_metrics['repeat_rate'] = product_metrics['sales_volume'] / product_metrics['unique_customers']\n",
        "    product_metrics['review_engagement'] = product_metrics['review_count'] / product_metrics['sales_volume']\n",
        "    \n",
        "    # Category-level analysis\n",
        "    category_metrics = data.groupby('category_clean').agg({\n",
        "        'product_id': 'nunique',\n",
        "        'price': ['count', 'mean', 'std'],\n",
        "        'total_item_value': ['sum', 'mean'],\n",
        "        'review_score': ['mean', 'std'],\n",
        "        'customer_id': 'nunique',\n",
        "        'freight_value': 'mean',\n",
        "        'profit_margin': 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    # Flatten category column names\n",
        "    category_metrics.columns = [\n",
        "        'unique_products', 'total_sales', 'avg_price', 'price_std',\n",
        "        'total_revenue', 'avg_order_value', 'avg_review_score', 'review_std',\n",
        "        'unique_customers', 'avg_freight', 'avg_profit_margin'\n",
        "    ]\n",
        "    \n",
        "    # Calculate category market share\n",
        "    total_revenue = category_metrics['total_revenue'].sum()\n",
        "    category_metrics['revenue_share'] = (category_metrics['total_revenue'] / total_revenue * 100).round(2)\n",
        "    \n",
        "    portfolio_analysis['product_metrics'] = product_metrics\n",
        "    portfolio_analysis['category_metrics'] = category_metrics\n",
        "    \n",
        "    return portfolio_analysis\n",
        "\n",
        "# Perform portfolio analysis\n",
        "portfolio_results = analyze_product_portfolio(product_df)\n",
        "product_metrics = portfolio_results['product_metrics']\n",
        "category_metrics = portfolio_results['category_metrics']\n",
        "\n",
        "print(f\"ðŸ“ˆ Portfolio Analysis Results:\")\n",
        "print(f\"   â€¢ Products analyzed: {len(product_metrics):,}\")\n",
        "print(f\"   â€¢ Categories analyzed: {len(category_metrics)}\")\n",
        "print(f\"   â€¢ Total revenue: R$ {category_metrics['total_revenue'].sum():,.2f}\")\n",
        "print(f\"   â€¢ Average product revenue: R$ {product_metrics['total_revenue'].mean():.2f}\")\n",
        "\n",
        "# Top performing categories\n",
        "top_categories = category_metrics.sort_values('total_revenue', ascending=False).head(10)\n",
        "print(f\"\\nðŸ† Top 10 Categories by Revenue:\")\n",
        "display(top_categories[['total_revenue', 'avg_price', 'avg_review_score', 'revenue_share', 'unique_customers']])\n",
        "\n",
        "# Product performance distribution analysis\n",
        "print(f\"\\nðŸ“Š Product Performance Distribution:\")\n",
        "performance_stats = product_metrics[['total_revenue', 'sales_volume', 'avg_review_score', 'repeat_rate']].describe()\n",
        "display(performance_stats)\n",
        "\n",
        "# Identify star products (high revenue + high satisfaction)\n",
        "revenue_threshold = product_metrics['total_revenue'].quantile(0.8)\n",
        "satisfaction_threshold = 4.0\n",
        "\n",
        "star_products = product_metrics[\n",
        "    (product_metrics['total_revenue'] >= revenue_threshold) & \n",
        "    (product_metrics['avg_review_score'] >= satisfaction_threshold)\n",
        "].sort_values('total_revenue', ascending=False)\n",
        "\n",
        "print(f\"\\nâ­ Star Products (High Revenue + High Satisfaction):\")\n",
        "print(f\"   â€¢ Star products identified: {len(star_products)}\")\n",
        "print(f\"   â€¢ Revenue contribution: R$ {star_products['total_revenue'].sum():,.2f}\")\n",
        "print(f\"   â€¢ Average satisfaction: {star_products['avg_review_score'].mean():.2f}\")\n",
        "\n",
        "if len(star_products) > 0:\n",
        "    print(f\"\\n   Top 5 Star Products:\")\n",
        "    display(star_products[['product_id', 'category', 'total_revenue', 'avg_review_score', 'sales_volume']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "product_lifecycle_analysis"
      },
      "outputs": [],
      "source": [
        "# Product Lifecycle and Performance Matrix Analysis\n",
        "print(\"ðŸ”„ Product Lifecycle and Performance Matrix Analysis\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def create_product_performance_matrix(product_metrics):\n",
        "    \"\"\"\n",
        "    Create BCG-style product performance matrix\n",
        "    \"\"\"\n",
        "    # Calculate market share and growth proxies\n",
        "    product_metrics['market_share_proxy'] = product_metrics['sales_volume'] / product_metrics['sales_volume'].sum()\n",
        "    product_metrics['growth_proxy'] = product_metrics['repeat_rate']  # Using repeat rate as growth indicator\n",
        "    \n",
        "    # Define thresholds (median splits)\n",
        "    share_median = product_metrics['market_share_proxy'].median()\n",
        "    growth_median = product_metrics['growth_proxy'].median()\n",
        "    \n",
        "    # Classify products into matrix quadrants\n",
        "    def classify_product(row):\n",
        "        share = row['market_share_proxy']\n",
        "        growth = row['growth_proxy']\n",
        "        \n",
        "        if share >= share_median and growth >= growth_median:\n",
        "            return 'Stars'  # High share, high growth\n",
        "        elif share >= share_median and growth < growth_median:\n",
        "            return 'Cash Cows'  # High share, low growth\n",
        "        elif share < share_median and growth >= growth_median:\n",
        "            return 'Question Marks'  # Low share, high growth\n",
        "        else:\n",
        "            return 'Dogs'  # Low share, low growth\n",
        "    \n",
        "    product_metrics['portfolio_category'] = product_metrics.apply(classify_product, axis=1)\n",
        "    \n",
        "    return product_metrics\n",
        "\n",
        "# Create performance matrix\n",
        "product_metrics_matrix = create_product_performance_matrix(product_metrics)\n",
        "\n",
        "# Analyze portfolio distribution\n",
        "portfolio_distribution = product_metrics_matrix['portfolio_category'].value_counts()\n",
        "portfolio_revenue = product_metrics_matrix.groupby('portfolio_category')['total_revenue'].sum().sort_values(ascending=False)\n",
        "\n",
        "print(f\"ðŸ“Š Product Portfolio Matrix Distribution:\")\n",
        "print(f\"\\nProduct Count by Category:\")\n",
        "for category, count in portfolio_distribution.items():\n",
        "    percentage = (count / len(product_metrics_matrix)) * 100\n",
        "    revenue = portfolio_revenue.get(category, 0)\n",
        "    print(f\"   â€¢ {category}: {count:,} products ({percentage:.1f}%) - Revenue: R$ {revenue:,.2f}\")\n",
        "\n",
        "# Detailed analysis by portfolio category\n",
        "portfolio_analysis = product_metrics_matrix.groupby('portfolio_category').agg({\n",
        "    'total_revenue': ['sum', 'mean', 'count'],\n",
        "    'avg_review_score': 'mean',\n",
        "    'sales_volume': 'mean',\n",
        "    'repeat_rate': 'mean',\n",
        "    'avg_profit_margin': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "# Flatten columns\n",
        "portfolio_analysis.columns = ['total_revenue', 'avg_revenue', 'product_count', \n",
        "                             'avg_satisfaction', 'avg_sales_volume', 'avg_repeat_rate', 'avg_profit_margin']\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Portfolio Category Performance Metrics:\")\n",
        "display(portfolio_analysis)\n",
        "\n",
        "# Strategic recommendations by category\n",
        "print(f\"\\nðŸŽ¯ Strategic Recommendations by Portfolio Category:\")\n",
        "\n",
        "for category in portfolio_distribution.index:\n",
        "    category_data = product_metrics_matrix[product_metrics_matrix['portfolio_category'] == category]\n",
        "    avg_revenue = category_data['total_revenue'].mean()\n",
        "    avg_satisfaction = category_data['avg_review_score'].mean()\n",
        "    \n",
        "    print(f\"\\n   {category.upper()}:\")\n",
        "    \n",
        "    if category == 'Stars':\n",
        "        print(f\"     Strategy: Invest and grow\")\n",
        "        print(f\"     Actions: Increase marketing spend, expand inventory, optimize pricing\")\n",
        "        print(f\"     Monitor: Maintain high satisfaction while scaling\")\n",
        "    \n",
        "    elif category == 'Cash Cows':\n",
        "        print(f\"     Strategy: Harvest and maintain\")\n",
        "        print(f\"     Actions: Optimize costs, maintain quality, steady promotion\")\n",
        "        print(f\"     Monitor: Profit margins and customer retention\")\n",
        "    \n",
        "    elif category == 'Question Marks':\n",
        "        print(f\"     Strategy: Selective investment\")\n",
        "        print(f\"     Actions: Test market expansion, improve product features\")\n",
        "        print(f\"     Monitor: Growth trajectory and market response\")\n",
        "    \n",
        "    else:  # Dogs\n",
        "        print(f\"     Strategy: Divest or revitalize\")\n",
        "        print(f\"     Actions: Discontinue poor performers, reposition promising ones\")\n",
        "        print(f\"     Monitor: Cost vs. revenue break-even\")\n",
        "    \n",
        "    print(f\"     Current performance: R$ {avg_revenue:.2f} avg revenue, {avg_satisfaction:.2f} satisfaction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category_analysis_section"
      },
      "source": [
        "## 4. Advanced Category Performance Analysis\n",
        "\n",
        "Deep dive into category-level performance patterns and insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "category_performance_analysis"
      },
      "outputs": [],
      "source": [
        "# Advanced Category Performance Analysis\n",
        "print(\"ðŸ·ï¸ Advanced Category Performance Analysis\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "def analyze_category_performance(data):\n",
        "    \"\"\"\n",
        "    Comprehensive category performance analysis\n",
        "    \"\"\"\n",
        "    # Enhanced category metrics\n",
        "    category_analysis = data.groupby('category_clean').agg({\n",
        "        'product_id': 'nunique',\n",
        "        'price': ['count', 'mean', 'std', 'min', 'max'],\n",
        "        'total_item_value': ['sum', 'mean'],\n",
        "        'review_score': ['mean', 'std', 'count'],\n",
        "        'customer_id': 'nunique',\n",
        "        'order_id': 'nunique',\n",
        "        'freight_value': 'mean',\n",
        "        'profit_margin': 'mean',\n",
        "        'product_weight_g': 'mean',\n",
        "        'product_volume_liters': 'mean',\n",
        "        'order_year': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
        "        'order_month': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]\n",
        "    }).round(2)\n",
        "    \n",
        "    # Flatten column names\n",
        "    category_analysis.columns = [\n",
        "        'unique_products', 'total_sales', 'avg_price', 'price_std', 'min_price', 'max_price',\n",
        "        'total_revenue', 'avg_order_value', 'avg_review_score', 'review_std', 'review_count',\n",
        "        'unique_customers', 'unique_orders', 'avg_freight', 'avg_profit_margin',\n",
        "        'avg_weight', 'avg_volume', 'peak_year', 'peak_month'\n",
        "    ]\n",
        "    \n",
        "    # Calculate additional business metrics\n",
        "    total_revenue = category_analysis['total_revenue'].sum()\n",
        "    category_analysis['revenue_share'] = (category_analysis['total_revenue'] / total_revenue * 100).round(2)\n",
        "    category_analysis['price_range'] = category_analysis['max_price'] - category_analysis['min_price']\n",
        "    category_analysis['sales_per_product'] = category_analysis['total_sales'] / category_analysis['unique_products']\n",
        "    category_analysis['customer_penetration'] = category_analysis['unique_customers'] / data['customer_id'].nunique() * 100\n",
        "    category_analysis['repeat_purchase_rate'] = category_analysis['total_sales'] / category_analysis['unique_customers']\n",
        "    \n",
        "    return category_analysis\n",
        "\n",
        "# Perform enhanced category analysis\n",
        "category_performance = analyze_category_performance(product_df)\n",
        "\n",
        "# Sort by revenue for display\n",
        "category_performance_sorted = category_performance.sort_values('total_revenue', ascending=False)\n",
        "\n",
        "print(f\"ðŸ“Š Enhanced Category Performance Results:\")\n",
        "print(f\"   â€¢ Categories analyzed: {len(category_performance)}\")\n",
        "print(f\"   â€¢ Total revenue analyzed: R$ {category_performance['total_revenue'].sum():,.2f}\")\n",
        "\n",
        "# Display top performing categories\n",
        "print(f\"\\nðŸ† Top 10 Categories - Comprehensive Performance:\")\n",
        "top_categories_enhanced = category_performance_sorted.head(10)\n",
        "display(top_categories_enhanced[['total_revenue', 'revenue_share', 'avg_price', 'avg_review_score', \n",
        "                               'unique_customers', 'repeat_purchase_rate']].round(2))\n",
        "\n",
        "# Category performance insights\n",
        "print(f\"\\nðŸ’¡ Category Performance Insights:\")\n",
        "\n",
        "# Most profitable category\n",
        "most_profitable = category_performance_sorted.index[0]\n",
        "most_profitable_margin = category_performance_sorted.loc[most_profitable, 'avg_profit_margin']\n",
        "print(f\"   â€¢ Most profitable category: {most_profitable} ({most_profitable_margin:.1%} margin)\")\n",
        "\n",
        "# Highest customer penetration\n",
        "highest_penetration = category_performance['customer_penetration'].idxmax()\n",
        "penetration_rate = category_performance.loc[highest_penetration, 'customer_penetration']\n",
        "print(f\"   â€¢ Highest customer penetration: {highest_penetration} ({penetration_rate:.1f}% of customers)\")\n",
        "\n",
        "# Most loyal customers (highest repeat rate)\n",
        "most_loyal = category_performance['repeat_purchase_rate'].idxmax()\n",
        "loyalty_rate = category_performance.loc[most_loyal, 'repeat_purchase_rate']\n",
        "print(f\"   â€¢ Highest customer loyalty: {most_loyal} ({loyalty_rate:.2f} purchases per customer)\")\n",
        "\n",
        "# Price analysis\n",
        "highest_avg_price = category_performance['avg_price'].idxmax()\n",
        "highest_price = category_performance.loc[highest_avg_price, 'avg_price']\n",
        "print(f\"   â€¢ Premium category: {highest_avg_price} (R$ {highest_price:.2f} avg price)\")\n",
        "\n",
        "# Satisfaction analysis\n",
        "highest_satisfaction = category_performance['avg_review_score'].idxmax()\n",
        "satisfaction_score = category_performance.loc[highest_satisfaction, 'avg_review_score']\n",
        "print(f\"   â€¢ Highest satisfaction: {highest_satisfaction} ({satisfaction_score:.2f} avg rating)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "category_competitive_analysis"
      },
      "outputs": [],
      "source": [
        "# Category Competitive Position Analysis\n",
        "print(\"âš”ï¸ Category Competitive Position Analysis\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "def analyze_category_competitive_position(category_data):\n",
        "    \"\"\"\n",
        "    Analyze competitive position of categories using multiple dimensions\n",
        "    \"\"\"\n",
        "    # Create competitive metrics\n",
        "    competitive_analysis = category_data.copy()\n",
        "    \n",
        "    # Calculate competitive scores (percentile rankings)\n",
        "    competitive_analysis['revenue_rank'] = category_data['total_revenue'].rank(pct=True)\n",
        "    competitive_analysis['satisfaction_rank'] = category_data['avg_review_score'].rank(pct=True)\n",
        "    competitive_analysis['growth_potential_rank'] = category_data['repeat_purchase_rate'].rank(pct=True)\n",
        "    competitive_analysis['margin_rank'] = category_data['avg_profit_margin'].rank(pct=True)\n",
        "    competitive_analysis['penetration_rank'] = category_data['customer_penetration'].rank(pct=True)\n",
        "    \n",
        "    # Calculate overall competitive score\n",
        "    competitive_analysis['competitive_score'] = (\n",
        "        competitive_analysis['revenue_rank'] * 0.3 +\n",
        "        competitive_analysis['satisfaction_rank'] * 0.2 +\n",
        "        competitive_analysis['growth_potential_rank'] * 0.2 +\n",
        "        competitive_analysis['margin_rank'] * 0.15 +\n",
        "        competitive_analysis['penetration_rank'] * 0.15\n",
        "    )\n",
        "    \n",
        "    # Classify competitive positions\n",
        "    def classify_position(score):\n",
        "        if score >= 0.8:\n",
        "            return 'Market Leader'\n",
        "        elif score >= 0.6:\n",
        "            return 'Strong Competitor'\n",
        "        elif score >= 0.4:\n",
        "            return 'Market Follower'\n",
        "        elif score >= 0.2:\n",
        "            return 'Niche Player'\n",
        "        else:\n",
        "            return 'Struggling'\n",
        "    \n",
        "    competitive_analysis['competitive_position'] = competitive_analysis['competitive_score'].apply(classify_position)\n",
        "    \n",
        "    return competitive_analysis\n",
        "\n",
        "# Perform competitive analysis\n",
        "competitive_positions = analyze_category_competitive_position(category_performance)\n",
        "\n",
        "# Display competitive positioning\n",
        "position_distribution = competitive_positions['competitive_position'].value_counts()\n",
        "print(f\"\\nðŸ Competitive Position Distribution:\")\n",
        "for position, count in position_distribution.items():\n",
        "    percentage = (count / len(competitive_positions)) * 100\n",
        "    print(f\"   â€¢ {position}: {count} categories ({percentage:.1f}%)\")\n",
        "\n",
        "# Top performers by competitive score\n",
        "top_competitive = competitive_positions.sort_values('competitive_score', ascending=False)\n",
        "print(f\"\\nðŸ¥‡ Top 10 Categories by Competitive Score:\")\n",
        "display(top_competitive[['competitive_score', 'competitive_position', 'total_revenue', \n",
        "                       'avg_review_score', 'avg_profit_margin']].head(10).round(3))\n",
        "\n",
        "# Detailed analysis by competitive position\n",
        "print(f\"\\nðŸ“Š Performance by Competitive Position:\")\n",
        "position_analysis = competitive_positions.groupby('competitive_position').agg({\n",
        "    'total_revenue': ['mean', 'sum'],\n",
        "    'avg_review_score': 'mean',\n",
        "    'avg_profit_margin': 'mean',\n",
        "    'customer_penetration': 'mean',\n",
        "    'repeat_purchase_rate': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "# Flatten columns\n",
        "position_analysis.columns = ['avg_revenue', 'total_revenue', 'avg_satisfaction', \n",
        "                           'avg_margin', 'avg_penetration', 'avg_loyalty']\n",
        "\n",
        "display(position_analysis)\n",
        "\n",
        "# Strategic recommendations by position\n",
        "print(f\"\\nðŸŽ¯ Strategic Recommendations by Competitive Position:\")\n",
        "\n",
        "for position in position_distribution.index:\n",
        "    position_categories = competitive_positions[competitive_positions['competitive_position'] == position]\n",
        "    category_count = len(position_categories)\n",
        "    \n",
        "    print(f\"\\n   {position.upper()} ({category_count} categories):\")\n",
        "    \n",
        "    if position == 'Market Leader':\n",
        "        print(f\"     Strategy: Defend and extend market leadership\")\n",
        "        print(f\"     Actions: Innovation, premium positioning, market expansion\")\n",
        "        print(f\"     Focus: Maintain quality while scaling operations\")\n",
        "    \n",
        "    elif position == 'Strong Competitor':\n",
        "        print(f\"     Strategy: Challenge for leadership or find differentiation\")\n",
        "        print(f\"     Actions: Competitive pricing, feature enhancement, niche focus\")\n",
        "        print(f\"     Focus: Identify and exploit leader weaknesses\")\n",
        "    \n",
        "    elif position == 'Market Follower':\n",
        "        print(f\"     Strategy: Follow leader or find profitable niches\")\n",
        "        print(f\"     Actions: Cost optimization, selective competition, specialization\")\n",
        "        print(f\"     Focus: Efficiency and targeted customer segments\")\n",
        "    \n",
        "    elif position == 'Niche Player':\n",
        "        print(f\"     Strategy: Dominate specific market segments\")\n",
        "        print(f\"     Actions: Deep specialization, customer intimacy, premium service\")\n",
        "        print(f\"     Focus: Become indispensable to target customers\")\n",
        "    \n",
        "    else:  # Struggling\n",
        "        print(f\"     Strategy: Turnaround or exit\")\n",
        "        print(f\"     Actions: Cost reduction, repositioning, or discontinuation\")\n",
        "        print(f\"     Focus: Determine viability and act decisively\")\n",
        "\n",
        "# Example categories for each position\n",
        "print(f\"\\nðŸ“‹ Example Categories by Position:\")\n",
        "for position in position_distribution.index:\n",
        "    examples = competitive_positions[competitive_positions['competitive_position'] == position].index[:3].tolist()\n",
        "    print(f\"   {position}: {', '.join(examples)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "product_relationship_section"
      },
      "source": [
        "## 5. Product Relationship and Cross-Selling Analysis\n",
        "\n",
        "Analyze product relationships and identify cross-selling opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "market_basket_analysis"
      },
      "outputs": [],
      "source": [
        "# Market Basket Analysis and Product Relationships\n",
        "print(\"ðŸ›’ Market Basket Analysis and Product Relationships\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def perform_market_basket_analysis(data):\n",
        "    \"\"\"\n",
        "    Perform market basket analysis to identify product relationships\n",
        "    \"\"\"\n",
        "    # Create order-product matrix\n",
        "    order_products = data.groupby('order_id')['category_clean'].apply(list).reset_index()\n",
        "    order_products['category_count'] = order_products['category_clean'].apply(len)\n",
        "    \n",
        "    # Focus on multi-item orders for association analysis\n",
        "    multi_item_orders = order_products[order_products['category_count'] > 1].copy()\n",
        "    \n",
        "    print(f\"ðŸ“Š Market Basket Analysis Overview:\")\n",
        "    print(f\"   â€¢ Total orders: {len(order_products):,}\")\n",
        "    print(f\"   â€¢ Multi-item orders: {len(multi_item_orders):,} ({len(multi_item_orders)/len(order_products)*100:.1f}%)\")\n",
        "    print(f\"   â€¢ Average items per multi-item order: {multi_item_orders['category_count'].mean():.1f}\")\n",
        "    \n",
        "    # Calculate category co-occurrence matrix\n",
        "    from collections import defaultdict, Counter\n",
        "    \n",
        "    # Count individual category frequency\n",
        "    category_counts = Counter()\n",
        "    for categories in multi_item_orders['category_clean']:\n",
        "        for category in set(categories):  # Use set to count each category once per order\n",
        "            category_counts[category] += 1\n",
        "    \n",
        "    # Count category pairs\n",
        "    pair_counts = Counter()\n",
        "    for categories in multi_item_orders['category_clean']:\n",
        "        unique_categories = list(set(categories))\n",
        "        for pair in combinations(sorted(unique_categories), 2):\n",
        "            pair_counts[pair] += 1\n",
        "    \n",
        "    # Calculate association metrics\n",
        "    associations = []\n",
        "    total_multi_orders = len(multi_item_orders)\n",
        "    \n",
        "    for (cat_a, cat_b), pair_count in pair_counts.items():\n",
        "        if pair_count >= 5:  # Minimum support threshold\n",
        "            support_a = category_counts[cat_a] / total_multi_orders\n",
        "            support_b = category_counts[cat_b] / total_multi_orders\n",
        "            support_ab = pair_count / total_multi_orders\n",
        "            \n",
        "            # Calculate confidence and lift\n",
        "            confidence_a_to_b = support_ab / support_a\n",
        "            confidence_b_to_a = support_ab / support_b\n",
        "            lift = support_ab / (support_a * support_b)\n",
        "            \n",
        "            associations.append({\n",
        "                'category_a': cat_a,\n",
        "                'category_b': cat_b,\n",
        "                'support': support_ab,\n",
        "                'confidence_a_to_b': confidence_a_to_b,\n",
        "                'confidence_b_to_a': confidence_b_to_a,\n",
        "                'lift': lift,\n",
        "                'pair_count': pair_count\n",
        "            })\n",
        "    \n",
        "    associations_df = pd.DataFrame(associations)\n",
        "    \n",
        "    return associations_df, category_counts, multi_item_orders\n",
        "\n",
        "# Perform market basket analysis\n",
        "associations, category_freq, multi_orders = perform_market_basket_analysis(product_df)\n",
        "\n",
        "if len(associations) > 0:\n",
        "    # Sort by lift for most interesting associations\n",
        "    top_associations = associations.sort_values('lift', ascending=False)\n",
        "    \n",
        "    print(f\"\\nðŸ” Top 15 Product Category Associations (by Lift):\")\n",
        "    display(top_associations.head(15)[['category_a', 'category_b', 'lift', 'confidence_a_to_b', \n",
        "                                     'confidence_b_to_a', 'support', 'pair_count']].round(3))\n",
        "    \n",
        "    # Identify strongest cross-selling opportunities\n",
        "    strong_associations = top_associations[\n",
        "        (top_associations['lift'] > 1.5) & \n",
        "        (top_associations['confidence_a_to_b'] > 0.3) &\n",
        "        (top_associations['pair_count'] >= 10)\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nðŸ’¡ Strong Cross-Selling Opportunities:\")\n",
        "    print(f\"   Criteria: Lift > 1.5, Confidence > 30%, Min 10 occurrences\")\n",
        "    print(f\"   Opportunities identified: {len(strong_associations)}\")\n",
        "    \n",
        "    if len(strong_associations) > 0:\n",
        "        print(f\"\\nðŸŽ¯ Recommended Cross-Selling Pairs:\")\n",
        "        for idx, row in strong_associations.head(10).iterrows():\n",
        "            print(f\"   â€¢ {row['category_a']} â†’ {row['category_b']}\")\n",
        "            print(f\"     Lift: {row['lift']:.2f}, Confidence: {row['confidence_a_to_b']:.1%}\")\n",
        "            print(f\"     Interpretation: Customers buying {row['category_a']} are {row['lift']:.1f}x more likely to buy {row['category_b']}\")\n",
        "            print()\n",
        "    \n",
        "    # Category popularity in multi-item orders\n",
        "    print(f\"\\nðŸ“Š Most Popular Categories in Multi-Item Orders:\")\n",
        "    popular_categories = pd.DataFrame(list(category_freq.items()), columns=['Category', 'Frequency'])\n",
        "    popular_categories['Percentage'] = (popular_categories['Frequency'] / len(multi_orders) * 100).round(1)\n",
        "    popular_categories = popular_categories.sort_values('Frequency', ascending=False)\n",
        "    \n",
        "    display(popular_categories.head(10))\n",
        "    \n",
        "else:\n",
        "    print(\"\\nâš ï¸ Insufficient data for meaningful association analysis\")\n",
        "    print(\"   This could indicate that customers typically buy single items\")\n",
        "    print(\"   or that the minimum support threshold is too high.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "product_network_analysis"
      },
      "outputs": [],
      "source": [
        "# Product Network Analysis for Relationship Visualization\n",
        "print(\"ðŸ•¸ï¸ Product Category Network Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "def create_product_network(associations_df, min_lift=1.2, min_confidence=0.2):\n",
        "    \"\"\"\n",
        "    Create a network graph of product category relationships\n",
        "    \"\"\"\n",
        "    if len(associations_df) == 0:\n",
        "        print(\"No associations available for network analysis\")\n",
        "        return None, None\n",
        "    \n",
        "    # Filter for meaningful relationships\n",
        "    filtered_associations = associations_df[\n",
        "        (associations_df['lift'] >= min_lift) & \n",
        "        (associations_df['confidence_a_to_b'] >= min_confidence)\n",
        "    ]\n",
        "    \n",
        "    if len(filtered_associations) == 0:\n",
        "        print(f\"No associations meet the criteria (lift >= {min_lift}, confidence >= {min_confidence})\")\n",
        "        return None, None\n",
        "    \n",
        "    # Create network graph\n",
        "    G = nx.Graph()\n",
        "    \n",
        "    # Add edges with weights\n",
        "    for _, row in filtered_associations.iterrows():\n",
        "        G.add_edge(\n",
        "            row['category_a'], \n",
        "            row['category_b'], \n",
        "            weight=row['lift'],\n",
        "            confidence=row['confidence_a_to_b'],\n",
        "            support=row['support']\n",
        "        )\n",
        "    \n",
        "    return G, filtered_associations\n",
        "\n",
        "# Create product network\n",
        "if len(associations) > 0:\n",
        "    product_network, network_associations = create_product_network(associations)\n",
        "    \n",
        "    if product_network is not None:\n",
        "        print(f\"\\nðŸ”— Product Category Network Statistics:\")\n",
        "        print(f\"   â€¢ Nodes (categories): {product_network.number_of_nodes()}\")\n",
        "        print(f\"   â€¢ Edges (relationships): {product_network.number_of_edges()}\")\n",
        "        print(f\"   â€¢ Network density: {nx.density(product_network):.3f}\")\n",
        "        \n",
        "        # Calculate network centrality measures\n",
        "        if product_network.number_of_nodes() > 0:\n",
        "            centrality_measures = {\n",
        "                'degree_centrality': nx.degree_centrality(product_network),\n",
        "                'betweenness_centrality': nx.betweenness_centrality(product_network),\n",
        "                'closeness_centrality': nx.closeness_centrality(product_network),\n",
        "                'eigenvector_centrality': nx.eigenvector_centrality(product_network, max_iter=1000)\n",
        "            }\n",
        "            \n",
        "            # Create centrality DataFrame\n",
        "            centrality_df = pd.DataFrame(centrality_measures).round(3)\n",
        "            centrality_df['avg_centrality'] = centrality_df.mean(axis=1)\n",
        "            centrality_df = centrality_df.sort_values('avg_centrality', ascending=False)\n",
        "            \n",
        "            print(f\"\\nðŸ“Š Category Network Centrality (Top 10):\")\n",
        "            print(f\"   Higher centrality = more connected to other categories\")\n",
        "            display(centrality_df.head(10))\n",
        "            \n",
        "            # Identify hub categories (high degree centrality)\n",
        "            hub_categories = centrality_df.sort_values('degree_centrality', ascending=False).head(5)\n",
        "            print(f\"\\nðŸŽ¯ Hub Categories (Most Connected):\")\n",
        "            for category, metrics in hub_categories.iterrows():\n",
        "                connections = product_network.degree(category)\n",
        "                print(f\"   â€¢ {category}: {connections} connections (centrality: {metrics['degree_centrality']:.3f})\")\n",
        "            \n",
        "            # Bridge categories (high betweenness centrality)\n",
        "            bridge_categories = centrality_df.sort_values('betweenness_centrality', ascending=False).head(5)\n",
        "            print(f\"\\nðŸŒ‰ Bridge Categories (Connect Different Groups):\")\n",
        "            for category, metrics in bridge_categories.iterrows():\n",
        "                print(f\"   â€¢ {category}: {metrics['betweenness_centrality']:.3f} betweenness centrality\")\n",
        "        \n",
        "        # Visualize network (if not too large)\n",
        "        if product_network.number_of_nodes() <= 20:\n",
        "            print(f\"\\nðŸŽ¨ Creating Network Visualization...\")\n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "            \n",
        "            # Create layout\n",
        "            pos = nx.spring_layout(product_network, k=3, iterations=50)\n",
        "            \n",
        "            # Draw nodes\n",
        "            node_sizes = [product_network.degree(node) * 300 + 300 for node in product_network.nodes()]\n",
        "            nx.draw_networkx_nodes(product_network, pos, node_size=node_sizes, \n",
        "                                 node_color='lightblue', alpha=0.7)\n",
        "            \n",
        "            # Draw edges with weights\n",
        "            edges = product_network.edges()\n",
        "            edge_weights = [product_network[u][v]['weight'] for u, v in edges]\n",
        "            nx.draw_networkx_edges(product_network, pos, width=[w*2 for w in edge_weights], \n",
        "                                 alpha=0.6, edge_color='gray')\n",
        "            \n",
        "            # Draw labels\n",
        "            labels = {node: node[:15] + '...' if len(node) > 15 else node for node in product_network.nodes()}\n",
        "            nx.draw_networkx_labels(product_network, pos, labels, font_size=8)\n",
        "            \n",
        "            plt.title('Product Category Relationship Network\\n(Node size = connections, Edge width = association strength)', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "            plt.axis('off')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        \n",
        "        else:\n",
        "            print(f\"\\nðŸ“Š Network too large for visualization ({product_network.number_of_nodes()} nodes)\")\n",
        "            print(f\"   Consider using specialized network visualization tools\")\n",
        "    \n",
        "    else:\n",
        "        print(\"\\nâš ï¸ No relationships meet the network criteria\")\n",
        "        print(\"   Try lowering the minimum lift or confidence thresholds\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No association data available for network analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "product_optimization_section"
      },
      "source": [
        "## 6. Product Performance Optimization and Recommendations\n",
        "\n",
        "Synthesize insights into actionable product optimization strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "product_optimization_analysis"
      },
      "outputs": [],
      "source": [
        "# Comprehensive Product Performance Optimization\n",
        "print(\"ðŸŽ¯ Comprehensive Product Performance Optimization\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def generate_product_optimization_recommendations(product_metrics, category_performance, competitive_positions, associations):\n",
        "    \"\"\"\n",
        "    Generate comprehensive product optimization recommendations\n",
        "    \"\"\"\n",
        "    recommendations = {\n",
        "        'portfolio_optimization': [],\n",
        "        'category_strategies': [],\n",
        "        'cross_selling': [],\n",
        "        'pricing_optimization': [],\n",
        "        'inventory_management': []\n",
        "    }\n",
        "    \n",
        "    # Portfolio optimization recommendations\n",
        "    total_revenue = product_metrics['total_revenue'].sum()\n",
        "    \n",
        "    # Identify underperforming products\n",
        "    low_performers = product_metrics[\n",
        "        (product_metrics['total_revenue'] < product_metrics['total_revenue'].quantile(0.2)) &\n",
        "        (product_metrics['avg_review_score'] < 3.5)\n",
        "    ]\n",
        "    \n",
        "    # Identify star performers\n",
        "    star_performers = product_metrics[\n",
        "        (product_metrics['total_revenue'] >= product_metrics['total_revenue'].quantile(0.8)) &\n",
        "        (product_metrics['avg_review_score'] >= 4.0)\n",
        "    ]\n",
        "    \n",
        "    recommendations['portfolio_optimization'] = [\n",
        "        f\"Focus resources on {len(star_performers)} star performers generating high revenue and satisfaction\",\n",
        "        f\"Review {len(low_performers)} underperforming products for potential discontinuation or improvement\",\n",
        "        f\"Star performers contribute R$ {star_performers['total_revenue'].sum():,.2f} ({star_performers['total_revenue'].sum()/total_revenue*100:.1f}% of revenue)\",\n",
        "        f\"Consider expanding product lines in categories with star performers\"\n",
        "    ]\n",
        "    \n",
        "    # Category-specific strategies\n",
        "    top_categories = category_performance.sort_values('total_revenue', ascending=False).head(5)\n",
        "    \n",
        "    for category in top_categories.index:\n",
        "        position = competitive_positions.loc[category, 'competitive_position']\n",
        "        revenue_share = category_performance.loc[category, 'revenue_share']\n",
        "        avg_margin = category_performance.loc[category, 'avg_profit_margin']\n",
        "        \n",
        "        strategy = f\"{category} ({position}): {revenue_share:.1f}% revenue share, {avg_margin:.1%} margin - \"\n",
        "        \n",
        "        if position == 'Market Leader':\n",
        "            strategy += \"Defend leadership through innovation and premium positioning\"\n",
        "        elif position == 'Strong Competitor':\n",
        "            strategy += \"Invest in differentiation and competitive advantages\"\n",
        "        else:\n",
        "            strategy += \"Focus on efficiency and niche opportunities\"\n",
        "        \n",
        "        recommendations['category_strategies'].append(strategy)\n",
        "    \n",
        "    # Cross-selling recommendations\n",
        "    if len(associations) > 0:\n",
        "        top_associations = associations.sort_values('lift', ascending=False).head(5)\n",
        "        \n",
        "        for _, assoc in top_associations.iterrows():\n",
        "            recommendation = f\"Cross-sell {assoc['category_b']} to {assoc['category_a']} customers \"\n",
        "            recommendation += f\"(Lift: {assoc['lift']:.2f}, Confidence: {assoc['confidence_a_to_b']:.1%})\"\n",
        "            recommendations['cross_selling'].append(recommendation)\n",
        "    else:\n",
        "        recommendations['cross_selling'].append(\"Insufficient data for cross-selling analysis\")\n",
        "    \n",
        "    # Pricing optimization\n",
        "    high_margin_categories = category_performance[category_performance['avg_profit_margin'] > 0.3]\n",
        "    low_margin_categories = category_performance[category_performance['avg_profit_margin'] < 0.1]\n",
        "    \n",
        "    recommendations['pricing_optimization'] = [\n",
        "        f\"Maintain premium pricing for {len(high_margin_categories)} high-margin categories\",\n",
        "        f\"Review pricing strategy for {len(low_margin_categories)} low-margin categories\",\n",
        "        f\"Consider dynamic pricing based on demand patterns and competition\",\n",
        "        f\"Implement value-based pricing for products with high customer satisfaction\"\n",
        "    ]\n",
        "    \n",
        "    # Inventory management\n",
        "    fast_movers = product_metrics[product_metrics['sales_volume'] >= product_metrics['sales_volume'].quantile(0.8)]\n",
        "    slow_movers = product_metrics[product_metrics['sales_volume'] <= product_metrics['sales_volume'].quantile(0.2)]\n",
        "    \n",
        "    recommendations['inventory_management'] = [\n",
        "        f\"Optimize inventory levels for {len(fast_movers)} fast-moving products\",\n",
        "        f\"Consider reducing inventory for {len(slow_movers)} slow-moving products\",\n",
        "        f\"Implement demand forecasting based on historical sales patterns\",\n",
        "        f\"Focus inventory investment on star performers and market leaders\"\n",
        "    ]\n",
        "    \n",
        "    return recommendations\n",
        "\n",
        "# Generate optimization recommendations\n",
        "optimization_recommendations = generate_product_optimization_recommendations(\n",
        "    product_metrics, category_performance, competitive_positions, associations\n",
        ")\n",
        "\n",
        "# Display comprehensive recommendations\n",
        "print(f\"\\nðŸ“‹ COMPREHENSIVE PRODUCT OPTIMIZATION RECOMMENDATIONS\")\n",
        "print(f\"=\" * 65)\n",
        "\n",
        "for category, recommendations in optimization_recommendations.items():\n",
        "    print(f\"\\nðŸŽ¯ {category.replace('_', ' ').upper()}:\")\n",
        "    for i, recommendation in enumerate(recommendations, 1):\n",
        "        print(f\"   {i}. {recommendation}\")\n",
        "\n",
        "# Calculate potential impact metrics\n",
        "print(f\"\\n\\nðŸ’° POTENTIAL BUSINESS IMPACT ANALYSIS\")\n",
        "print(f\"=\" * 50)\n",
        "\n",
        "total_revenue = product_metrics['total_revenue'].sum()\n",
        "total_products = len(product_metrics)\n",
        "\n",
        "# Portfolio optimization impact\n",
        "star_revenue = product_metrics[\n",
        "    (product_metrics['total_revenue'] >= product_metrics['total_revenue'].quantile(0.8)) &\n",
        "    (product_metrics['avg_review_score'] >= 4.0)\n",
        "]['total_revenue'].sum()\n",
        "\n",
        "underperformer_revenue = product_metrics[\n",
        "    (product_metrics['total_revenue'] < product_metrics['total_revenue'].quantile(0.2)) &\n",
        "    (product_metrics['avg_review_score'] < 3.5)\n",
        "]['total_revenue'].sum()\n",
        "\n",
        "print(f\"ðŸ“Š Current Portfolio Metrics:\")\n",
        "print(f\"   â€¢ Total revenue: R$ {total_revenue:,.2f}\")\n",
        "print(f\"   â€¢ Star performer revenue: R$ {star_revenue:,.2f} ({star_revenue/total_revenue*100:.1f}%)\")\n",
        "print(f\"   â€¢ Underperformer revenue: R$ {underperformer_revenue:,.2f} ({underperformer_revenue/total_revenue*100:.1f}%)\")\n",
        "\n",
        "# Estimated optimization impact\n",
        "print(f\"\\nðŸŽ¯ Estimated Optimization Impact (12-month projection):\")\n",
        "print(f\"   â€¢ Focus on star performers: +15-25% revenue growth = R$ {star_revenue * 0.2:,.2f}\")\n",
        "print(f\"   â€¢ Cross-selling implementation: +5-10% revenue growth = R$ {total_revenue * 0.075:,.2f}\")\n",
        "print(f\"   â€¢ Underperformer optimization: +3-8% margin improvement\")\n",
        "print(f\"   â€¢ Category positioning: +10-20% in targeted categories\")\n",
        "\n",
        "# Implementation priorities\n",
        "print(f\"\\nâš¡ IMPLEMENTATION PRIORITIES\")\n",
        "print(f\"=\" * 35)\n",
        "print(f\"\\nðŸ¥‡ HIGH PRIORITY (Immediate - 1-2 months):\")\n",
        "print(f\"   â€¢ Optimize inventory for star performers\")\n",
        "print(f\"   â€¢ Implement cross-selling for top associations\")\n",
        "print(f\"   â€¢ Review pricing for low-margin categories\")\n",
        "\n",
        "print(f\"\\nðŸ¥ˆ MEDIUM PRIORITY (3-6 months):\")\n",
        "print(f\"   â€¢ Develop category-specific strategies\")\n",
        "print(f\"   â€¢ Improve or discontinue underperformers\")\n",
        "print(f\"   â€¢ Enhance product mix in market leader categories\")\n",
        "\n",
        "print(f\"\\nðŸ¥‰ LOW PRIORITY (6-12 months):\")\n",
        "print(f\"   â€¢ Explore new product development\")\n",
        "print(f\"   â€¢ Long-term competitive positioning\")\n",
        "print(f\"   â€¢ Advanced analytics implementation\")\n",
        "\n",
        "print(f\"\\nâœ… Product Performance Analysis Complete!\")\n",
        "print(f\"   Ready for time series analysis and advanced forecasting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_part2"
      },
      "source": [
        "## Summary - Product Performance Metrics and Insights\n",
        "\n",
        "### What We've Accomplished\n",
        "\n",
        "1. **âœ… Comprehensive Product Portfolio Analysis**: Analyzed 30,000+ product transactions across multiple performance dimensions\n",
        "2. **âœ… BCG-Style Performance Matrix**: Classified products into Stars, Cash Cows, Question Marks, and Dogs\n",
        "3. **âœ… Advanced Category Analysis**: Deep competitive positioning and market share analysis\n",
        "4. **âœ… Market Basket Analysis**: Identified cross-selling opportunities through association rules\n",
        "5. **âœ… Product Network Analysis**: Visualized category relationships and identified hub categories\n",
        "6. **âœ… Strategic Optimization Framework**: Created actionable recommendations with impact projections\n",
        "\n",
        "### Key Business Insights Discovered\n",
        "\n",
        "**Product Performance:**\n",
        "- Clear identification of star performers driving revenue and satisfaction\n",
        "- Underperformer analysis for optimization or discontinuation\n",
        "- Category competitive positioning and market dynamics\n",
        "\n",
        "**Cross-Selling Opportunities:**\n",
        "- Data-driven product association rules\n",
        "- Network analysis revealing category relationship patterns\n",
        "- Quantified cross-selling potential with confidence metrics\n",
        "\n",
        "**Strategic Recommendations:**\n",
        "- Portfolio optimization priorities with revenue impact\n",
        "- Category-specific competitive strategies\n",
        "- Pricing and inventory optimization opportunities\n",
        "\n",
        "### Advanced Techniques Mastered\n",
        "\n",
        "- **BCG Matrix Analysis**: Strategic product portfolio classification\n",
        "- **Association Rule Mining**: Market basket analysis with lift and confidence\n",
        "- **Network Analysis**: Product relationship visualization and centrality measures\n",
        "- **Competitive Positioning**: Multi-dimensional performance scoring\n",
        "- **Business Impact Modeling**: Quantified optimization recommendations\n",
        "\n",
        "### Next Steps\n",
        "In Part 3, we'll explore:\n",
        "- Time series patterns in order data\n",
        "- Seasonal trends and forecasting\n",
        "- Advanced temporal analysis for business planning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercises_part2"
      },
      "source": [
        "## ðŸŽ¯ Practice Exercises - Product Performance Analysis\n",
        "\n",
        "Master product analytics techniques:\n",
        "\n",
        "1. **Custom Portfolio Matrix**: Create your own product classification system using different metrics\n",
        "\n",
        "2. **Advanced Association Analysis**: Implement additional association metrics (conviction, cosine similarity)\n",
        "\n",
        "3. **Price Elasticity Analysis**: Analyze how price changes affect demand patterns\n",
        "\n",
        "4. **Product Lifecycle Modeling**: Create models to identify product lifecycle stages\n",
        "\n",
        "5. **Recommendation Engine**: Build a simple product recommendation system based on associations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_space_part2"
      },
      "outputs": [],
      "source": [
        "# Exercise Space - Product Performance Analysis\n",
        "# Use this space to practice the product analytics techniques\n",
        "\n",
        "# Exercise 1: Custom Portfolio Matrix\n",
        "# Create alternative product classification systems\n",
        "\n",
        "# Exercise 2: Advanced Association Analysis\n",
        "# Implement additional association metrics\n",
        "\n",
        "# Exercise 3: Price Elasticity Analysis\n",
        "# Analyze price-demand relationships\n",
        "\n",
        "# Exercise 4: Product Lifecycle Modeling\n",
        "# Identify product lifecycle stages\n",
        "\n",
        "# Exercise 5: Recommendation Engine\n",
        "# Build product recommendation system"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
